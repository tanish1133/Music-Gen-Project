{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "from music21 import *\n",
    "import os \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import tensor\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import tensorflow as tf\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "\n",
    "notes_df = pd.read_csv ('Dataset/notes.csv')\n",
    "test_df = pd.read_csv ('Dataset/testset.csv')\n",
    "\n",
    "data_test = test_df[['x_test','future']].to_numpy()\n",
    "\n",
    "x_test_string = data_test[:,0]\n",
    "y_test_string = data_test[:,1]\n",
    "x_test = []\n",
    "y_test = []\n",
    "for i in x_test_string:\n",
    "\n",
    "    b = \"[]\\n\"\n",
    "    for char in b:\n",
    "        i = i.replace(char, \"\")\n",
    "    input_x_test = [int(j) for j in i.split()]\n",
    "    x_test.append(input_x_test)\n",
    "\n",
    "for i in y_test_string:\n",
    "\n",
    "    b = \"[]\\n\"\n",
    "    for char in b:\n",
    "        i = i.replace(char, \"\")\n",
    "    input_y_test = [int(j) for j in i.split()]\n",
    "    y_test.append(input_y_test)\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "    \n",
    "\n",
    "\n",
    "notes_ = notes_df.to_numpy()[:,1]\n",
    "unique_notes = dict(enumerate(notes_.flatten(), 0))\n",
    "# unique_notes = {value : key for (key, value) in unique_notes_reverse.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MusicDataset import *\n",
    "test_set = MusicDataset(x_test,y_test)\n",
    "testloader = torch.utils.data.DataLoader(test_set, batch_size=1,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence(\n",
      "  (embedding): Embedding(173, 100)\n",
      "  (lstm): LSTM(100, 256, num_layers=3, batch_first=True)\n",
      "  (linear1): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (softmax): Softmax(dim=None)\n",
      "  (linear3): Linear(in_features=128, out_features=173, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from Models import Wavenet,LSTM\n",
    "Net = torch.load('Trained_Model/model.pth')\n",
    "print(Net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m correct_preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      3\u001b[0m future_preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtestloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28minput\u001b[39m , label \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m      7\u001b[0m     cumm_output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;28mlen\u001b[39m(unique_notes))\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:438\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    436\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 438\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:386\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    385\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 386\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:1039\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1032\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1033\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1034\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1039\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1040\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\multiprocessing\\context.py:336\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_win32\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[1;32m--> 336\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     reduction\u001b[38;5;241m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 93\u001b[0m     \u001b[43mreduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_child\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdump\u001b[39m(obj, file, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     \u001b[43mForkingPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "total_preds = 0\n",
    "correct_preds = 0\n",
    "future_preds = 8\n",
    "for i, data in enumerate(testloader, 0):\n",
    "\n",
    "    input , label = data\n",
    "    cumm_output = torch.zeros(0,len(unique_notes)).to(device)\n",
    "    cumm_label  = np.array([],dtype=int)\n",
    "    for k in range(future_preds):\n",
    "        output = Net(input.to(device),input.shape[0])\n",
    "        cumm_output = torch.cat((cumm_output,output))\n",
    "        cumm_label = np.concatenate((cumm_label,label[:,k]))\n",
    "        next_preds = np.argmax(output.cpu().detach().numpy(),axis=1)\n",
    "        total_preds += input.shape[0]\n",
    "        correct_preds += torch.sum(torch.argmax(output,1) == label[:,k].to(device))\n",
    "        input = input.cpu().detach().numpy()\n",
    "        input = torch.from_numpy(np.array([np.append(j,next_preds[ind]) \n",
    "                                               for ind,j in enumerate(input)])[:,1:]) \n",
    "test_acc =  float(correct_preds)/float(total_preds) *100 \n",
    "testreport =\"Testing Accuracy : \\n correct predictions  : {} \\n total predictions : {} \\n Testing Accuracy : {} \\n ------------------------\\n\".format(correct_preds,total_preds,test_acc)\n",
    "print(testreport)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################Errrrrrrror\n",
    "# # Time to generate some Music!!!\n",
    "# import random\n",
    "# from Dataset import midi_helper \n",
    "# for j in range(10):\n",
    "#     index = random.randint(0,len(x_test))\n",
    "#     print(\"Taking the seed tune as follows:\")\n",
    "#     print(x_test[index])\n",
    "#     tune = x_test[index]\n",
    "#     input = np.empty((1,32),dtype=int)\n",
    "#     input[0] = tune\n",
    "#     input = torch.from_numpy(input)\n",
    "#     next_preds = 64\n",
    "#     for i in range(next_preds):\n",
    "#         output = Net(input.to(device),input.shape[0])\n",
    "#         next_preds = np.argmax(output.cpu().detach().numpy(),axis=1)\n",
    "#         input = input.cpu().detach().numpy()\n",
    "#         input = torch.from_numpy(np.array([np.append(j,next_preds[ind]) \n",
    "#                                                    for ind,j in enumerate(input)])[:,1:]) \n",
    "\n",
    "#         tune = np.insert(tune,-1,next_preds[0])\n",
    "#     tune = [unique_notes[i] for i in tune]\n",
    "#     path = './Outputs/music'+str(j)+'.midi'\n",
    "#     midi_helper.convert_to_midi(tune,path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taking the seed tune as follows:\n",
      "[ 71 126 108 105 105  25 171 171 171  14 171 114 171  65 109 159 109 159\n",
      " 109  98 116 125  32 125  56 129  56  89  16  89 129  89]\n",
      "Taking the seed tune as follows:\n",
      "[144  76 164 100  76 131 160  52  46   4  16  11  76  76  50 103 119 167\n",
      "  56 103 119 167  56 103 119 167  56 103 119 167  56 103]\n",
      "Taking the seed tune as follows:\n",
      "[146 171 106 162   4 146 106 162  96   8 146 171 162  19 146 171 162  19\n",
      " 146 171 162  19 146 171 162  19 106 162 130 167 106 162]\n",
      "Taking the seed tune as follows:\n",
      "[ 16  98 109   6  10  97 163 146  10   9 115 111  34   6  45 109  29  98\n",
      "  11 125   4 171 108 117  43 172 112 143  13  51   0 141]\n",
      "Taking the seed tune as follows:\n",
      "[ 97 106  62  29 129  51  62 155  97 140  62 112  97 140  62 112  97 135\n",
      "  62 117  97 135  62 117  97   4  62 145  97   4  62 145]\n",
      "Taking the seed tune as follows:\n",
      "[129  68  70   2  19  71  73   2  71  73   2  72   2   2   2   2   2  94\n",
      " 131  94  94  94  94  94  80  58 157  80 157  80  49 157]\n",
      "Taking the seed tune as follows:\n",
      "[ 73  50 109 109 109  85 161  39  39  39 167 161  39  36 119   8  50 109\n",
      " 118 161  39  53 101  19  19  19 101  19  19  19  22 107]\n",
      "Taking the seed tune as follows:\n",
      "[130  67  88  29  27 162 155 106 155  34 155 106  27 167 155  45 155  96\n",
      " 155  45  27  20 155  51 106 155  27  82 128 106 155  79]\n",
      "Taking the seed tune as follows:\n",
      "[152  72 152  72   4 146   4 146   4 146 130 167   4 146  53  73  53  73\n",
      "  20  20  20  20  20  20  10  10  20  20  79  79  79  79]\n",
      "Taking the seed tune as follows:\n",
      "[163 162 163 167 163  26 102 163  39 163  48  97 163 167 163  99 102 163\n",
      "  39 163   3  97 163 167 163  26   8  98 102  98  19  98]\n"
     ]
    }
   ],
   "source": [
    "# Time to generate some Music!!!\n",
    "import random\n",
    "from Dataset import midi_helper \n",
    "\n",
    "# Assuming convert_to_midi() function only takes one argument\n",
    "for j in range(10):\n",
    "    index = random.randint(0, len(x_test))\n",
    "    print(\"Taking the seed tune as follows:\")\n",
    "    print(x_test[index])\n",
    "    tune = x_test[index]\n",
    "    input = np.empty((1, 32), dtype=int)\n",
    "    input[0] = tune\n",
    "    input = torch.from_numpy(input)\n",
    "    next_preds = 64\n",
    "    for i in range(next_preds):\n",
    "        output = Net(input.to(device), input.shape[0])\n",
    "        next_preds = np.argmax(output.cpu().detach().numpy(), axis=1)\n",
    "        input = input.cpu().detach().numpy()\n",
    "        input = torch.from_numpy(np.array([np.append(j, next_preds[ind]) \n",
    "                                           for ind, j in enumerate(input)])[:, 1:])\n",
    "        tune = np.insert(tune, -1, next_preds[0])\n",
    "    tune = [unique_notes[i] for i in tune]\n",
    "    path = './Outputs/music1'+str(j)+'.midi'\n",
    "    midi_helper.convert_to_midi(tune)  # Remove the path argument\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taking the seed tune as follows:\n",
      "[ 38  79  53  78  78  74  44  78  78  91 112 112  91 140 140  74 112 112\n",
      "  74 140 140  83  83 112 112  83  83 140 140  17  69  91]\n",
      "Saving file at: ./Outputs/music0.midi\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "convert_to_midi() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 31\u001b[0m\n\u001b[0;32m     29\u001b[0m path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_directory, filename)  \u001b[38;5;66;03m# Get the full path\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaving file at:\u001b[39m\u001b[38;5;124m\"\u001b[39m, path)  \u001b[38;5;66;03m# Display the full path\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m \u001b[43mmidi_helper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_midi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtune\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: convert_to_midi() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from Dataset import midi_helper \n",
    "\n",
    "# Assuming convert_to_midi() function only takes one argument\n",
    "output_directory = './Outputs/'\n",
    "os.makedirs(output_directory, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "\n",
    "for j in range(10):\n",
    "    index = random.randint(0, len(x_test))\n",
    "    print(\"Taking the seed tune as follows:\")\n",
    "    print(x_test[index])\n",
    "    tune = x_test[index]\n",
    "    input = np.empty((1, 32), dtype=int)\n",
    "    input[0] = tune\n",
    "    input = torch.from_numpy(input)\n",
    "    next_preds = 64\n",
    "    for i in range(next_preds):\n",
    "        output = Net(input.to(device), input.shape[0])\n",
    "        next_preds = np.argmax(output.cpu().detach().numpy(), axis=1)\n",
    "        input = input.cpu().detach().numpy()\n",
    "        input = torch.from_numpy(np.array([np.append(j, next_preds[ind]) \n",
    "                                           for ind, j in enumerate(input)])[:, 1:])\n",
    "        tune = np.insert(tune, -1, next_preds[0])\n",
    "    tune = [unique_notes[i] for i in tune]\n",
    "    filename = f'music{j}.midi'\n",
    "    path = os.path.join(output_directory, filename)  # Get the full path\n",
    "    print(\"Saving file at:\", path)  # Display the full path\n",
    "    midi_helper.convert_to_midi(tune, path)  # Provide the full path argument\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install music21\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taking the seed tune as follows:\n",
      "[145  11 145 145 163  69 135 163  69  91  17 163  69  91  17 163  69  36\n",
      "  98   2 103   2   2   2  98   2 149 140  39  91  95 130]\n",
      "Taking the seed tune as follows:\n",
      "[155  34   0 130 155   0 120 108  88 120  38 172 111 151 120 117 128 141\n",
      " 130   0  51  29  13  51 128   4 141 128 151  43 115 120]\n",
      "Taking the seed tune as follows:\n",
      "[ 11   6 163 111 163   6 163  11  39 163  11   6  29 163  11 111   4 163\n",
      " 108 162  43 163 117 162  11 111   4  97 111  97  34  97]\n",
      "Taking the seed tune as follows:\n",
      "[109 135 146   4   8  34 109 135 146 130 125  34 109 108 167  34 116  43\n",
      "  31  61  52  47  25 116 116   9   9  77  33 116  25 116]\n",
      "Taking the seed tune as follows:\n",
      "[ 84  67  67  44 171 165  23 165  99 165  99  32 134  26  72 134  48  66\n",
      "  26 134  48   6  63 154  72  26  85  48  63  72 154  52]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from Dataset import midi_helper \n",
    "\n",
    "# Assuming convert_to_midi() function only takes one argument\n",
    "output_directory = './Outpu/'\n",
    "os.makedirs(output_directory, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "\n",
    "for j in range(5):\n",
    "    index = random.randint(0, len(x_test))\n",
    "    print(\"Taking the seed tune as follows:\")\n",
    "    print(x_test[index])\n",
    "    tune = x_test[index]\n",
    "    input = np.empty((1, 32), dtype=int)\n",
    "    input[0] = tune\n",
    "    input = torch.from_numpy(input)\n",
    "    next_preds = 64\n",
    "    for i in range(next_preds):\n",
    "        output = Net(input.to(device), input.shape[0])\n",
    "        next_preds = np.argmax(output.cpu().detach().numpy(), axis=1)\n",
    "        input = input.cpu().detach().numpy()\n",
    "        input = torch.from_numpy(np.array([np.append(j, next_preds[ind]) \n",
    "                                           for ind, j in enumerate(input)])[:, 1:])\n",
    "        tune = np.insert(tune, -1, next_preds[0])\n",
    "    tune = [unique_notes[i] for i in tune]\n",
    "#     filename = f'music{j}.midi'\n",
    "#     path = os.path.join(output_directory, filename)  # Get the full path\n",
    "#     print(\"Saving file at:\", path)  # Display the full path\n",
    "    midi_helper.convert_to_midi(tune)  # Remove the path argument\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "from pretty_midi import PrettyMIDI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install midi2audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'midi2audio'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmidi2audio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FluidSynth\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#Play MIDI\u001b[39;00m\n\u001b[0;32m      4\u001b[0m fs \u001b[38;5;241m=\u001b[39m FluidSynth()\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'midi2audio'"
     ]
    }
   ],
   "source": [
    "from midi2audio import FluidSynth\n",
    "\n",
    "#Play MIDI\n",
    "fs = FluidSynth()\n",
    "fs.midi_to_audio('music.mid', 'output.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.2 (SDL 2.28.3, Python 3.10.9)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "#import pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install MIDIUtil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install mido==1.2.9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install musicpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from musicpy import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import mido\n",
    "# mid = mido.MidiFile('music.mid')\n",
    "# for msg in mid.play():\n",
    "#     port.send(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lay(\"music.mid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taking the seed tune as follows:\n",
      "[157  94  85  11 135   8 117  85 135 103 172 147 162  94 147 162  94 145\n",
      "  11 162  11  94 145  11 162 130 103  11 145  17 162  94]\n",
      "Taking the seed tune as follows:\n",
      "[ 34 109  45   6  29  97  62  32  29  97 115 125 130 167  65  42  65  42\n",
      "  65  42  65  42 130 153 167  60   9   9  34 109  45   6]\n",
      "Taking the seed tune as follows:\n",
      "[106  32 117  91  73 117   2 113  84   2  71  17 161  17 123  17 161  71\n",
      "  84  36  71  17 102 123  17 102 123   8 103   8 103 140]\n",
      "Taking the seed tune as follows:\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 8014 is out of bounds for axis 0 with size 8014",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[63], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m index \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(x_test))\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTaking the seed tune as follows:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mx_test\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[0;32m     15\u001b[0m tune \u001b[38;5;241m=\u001b[39m x_test[index]\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m32\u001b[39m), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: index 8014 is out of bounds for axis 0 with size 8014"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from Dataset import midi_helper \n",
    "\n",
    "# Assuming convert_to_midi() function only takes one argument\n",
    "output_directory = './Outpu/'\n",
    "os.makedirs(output_directory, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "\n",
    "for j in range(10):\n",
    "    index = random.randint(0, len(x_test))\n",
    "    print(\"Taking the seed tune as follows:\")\n",
    "    print(x_test[index])\n",
    "    tune = x_test[index]\n",
    "    input = np.empty((1, 32), dtype=int)\n",
    "    input[0] = tune\n",
    "    input = torch.from_numpy(input)\n",
    "    next_preds = 64\n",
    "    for i in range(next_preds):\n",
    "        output = Net(input.to(device), input.shape[0])\n",
    "        next_preds = np.argmax(output.cpu().detach().numpy(), axis=1)\n",
    "        input = input.cpu().detach().numpy()\n",
    "        input = torch.from_numpy(np.array([np.append(j, next_preds[ind]) \n",
    "                                           for ind, j in enumerate(input)])[:, 1:])\n",
    "        tune = np.insert(tune, -1, next_preds[0])\n",
    "    tune = [unique_notes[i] for i in tune]\n",
    "#     filename = f'music{j}.midi'\n",
    "#     path = os.path.join(output_directory, filename)  # Get the full path\n",
    "#     print(\"Saving file at:\", path)  # Display the full path\n",
    "    midi_helper.convert_to_midi(tune)  # Remove the path argument\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_filename = r'music.mid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Admin\\\\Python\\\\Music_generation\\\\Music-Gen-AI-main\\\\music'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
