{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "from music21 import *\n",
    "import os \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import tensor\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import tensorflow as tf\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "\n",
    "notes_df = pd.read_csv ('Dataset/notes.csv')\n",
    "test_df = pd.read_csv ('Dataset/testset.csv')\n",
    "\n",
    "data_test = test_df[['x_test','future']].to_numpy()\n",
    "\n",
    "x_test_string = data_test[:,0]\n",
    "y_test_string = data_test[:,1]\n",
    "x_test = []\n",
    "y_test = []\n",
    "for i in x_test_string:\n",
    "\n",
    "    b = \"[]\\n\"\n",
    "    for char in b:\n",
    "        i = i.replace(char, \"\")\n",
    "    input_x_test = [int(j) for j in i.split()]\n",
    "    x_test.append(input_x_test)\n",
    "\n",
    "for i in y_test_string:\n",
    "\n",
    "    b = \"[]\\n\"\n",
    "    for char in b:\n",
    "        i = i.replace(char, \"\")\n",
    "    input_y_test = [int(j) for j in i.split()]\n",
    "    y_test.append(input_y_test)\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "    \n",
    "\n",
    "\n",
    "notes_ = notes_df.to_numpy()[:,1]\n",
    "unique_notes = dict(enumerate(notes_.flatten(), 0))\n",
    "# unique_notes = {value : key for (key, value) in unique_notes_reverse.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MusicDataset import *\n",
    "test_set = MusicDataset(x_test,y_test)\n",
    "testloader = torch.utils.data.DataLoader(test_set, batch_size=1,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence(\n",
      "  (embedding): Embedding(173, 100)\n",
      "  (lstm): LSTM(100, 256, num_layers=3, batch_first=True)\n",
      "  (linear1): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (softmax): Softmax(dim=None)\n",
      "  (linear3): Linear(in_features=128, out_features=173, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from Models import Wavenet,LSTM\n",
    "Net = torch.load('Trained_Model/model.pth')\n",
    "print(Net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m correct_preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      3\u001b[0m future_preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtestloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28minput\u001b[39m , label \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m      7\u001b[0m     cumm_output \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;28mlen\u001b[39m(unique_notes))\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:438\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    436\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 438\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:386\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    385\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 386\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:1039\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1032\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1033\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1034\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1039\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1040\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\multiprocessing\\context.py:336\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_win32\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[1;32m--> 336\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     reduction\u001b[38;5;241m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 93\u001b[0m     \u001b[43mreduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_child\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdump\u001b[39m(obj, file, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     \u001b[43mForkingPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "total_preds = 0\n",
    "correct_preds = 0\n",
    "future_preds = 8\n",
    "for i, data in enumerate(testloader, 0):\n",
    "\n",
    "    input , label = data\n",
    "    cumm_output = torch.zeros(0,len(unique_notes)).to(device)\n",
    "    cumm_label  = np.array([],dtype=int)\n",
    "    for k in range(future_preds):\n",
    "        output = Net(input.to(device),input.shape[0])\n",
    "        cumm_output = torch.cat((cumm_output,output))\n",
    "        cumm_label = np.concatenate((cumm_label,label[:,k]))\n",
    "        next_preds = np.argmax(output.cpu().detach().numpy(),axis=1)\n",
    "        total_preds += input.shape[0]\n",
    "        correct_preds += torch.sum(torch.argmax(output,1) == label[:,k].to(device))\n",
    "        input = input.cpu().detach().numpy()\n",
    "        input = torch.from_numpy(np.array([np.append(j,next_preds[ind]) \n",
    "                                               for ind,j in enumerate(input)])[:,1:]) \n",
    "test_acc =  float(correct_preds)/float(total_preds) *100 \n",
    "testreport =\"Testing Accuracy : \\n correct predictions  : {} \\n total predictions : {} \\n Testing Accuracy : {} \\n ------------------------\\n\".format(correct_preds,total_preds,test_acc)\n",
    "print(testreport)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################Errrrrrrror\n",
    "# # Time to generate some Music!!!\n",
    "# import random\n",
    "# from Dataset import midi_helper \n",
    "# for j in range(10):\n",
    "#     index = random.randint(0,len(x_test))\n",
    "#     print(\"Taking the seed tune as follows:\")\n",
    "#     print(x_test[index])\n",
    "#     tune = x_test[index]\n",
    "#     input = np.empty((1,32),dtype=int)\n",
    "#     input[0] = tune\n",
    "#     input = torch.from_numpy(input)\n",
    "#     next_preds = 64\n",
    "#     for i in range(next_preds):\n",
    "#         output = Net(input.to(device),input.shape[0])\n",
    "#         next_preds = np.argmax(output.cpu().detach().numpy(),axis=1)\n",
    "#         input = input.cpu().detach().numpy()\n",
    "#         input = torch.from_numpy(np.array([np.append(j,next_preds[ind]) \n",
    "#                                                    for ind,j in enumerate(input)])[:,1:]) \n",
    "\n",
    "#         tune = np.insert(tune,-1,next_preds[0])\n",
    "#     tune = [unique_notes[i] for i in tune]\n",
    "#     path = './Outputs/music'+str(j)+'.midi'\n",
    "#     midi_helper.convert_to_midi(tune,path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taking the seed tune as follows:\n",
      "[ 71 126 108 105 105  25 171 171 171  14 171 114 171  65 109 159 109 159\n",
      " 109  98 116 125  32 125  56 129  56  89  16  89 129  89]\n",
      "Taking the seed tune as follows:\n",
      "[144  76 164 100  76 131 160  52  46   4  16  11  76  76  50 103 119 167\n",
      "  56 103 119 167  56 103 119 167  56 103 119 167  56 103]\n",
      "Taking the seed tune as follows:\n",
      "[146 171 106 162   4 146 106 162  96   8 146 171 162  19 146 171 162  19\n",
      " 146 171 162  19 146 171 162  19 106 162 130 167 106 162]\n",
      "Taking the seed tune as follows:\n",
      "[ 16  98 109   6  10  97 163 146  10   9 115 111  34   6  45 109  29  98\n",
      "  11 125   4 171 108 117  43 172 112 143  13  51   0 141]\n",
      "Taking the seed tune as follows:\n",
      "[ 97 106  62  29 129  51  62 155  97 140  62 112  97 140  62 112  97 135\n",
      "  62 117  97 135  62 117  97   4  62 145  97   4  62 145]\n",
      "Taking the seed tune as follows:\n",
      "[129  68  70   2  19  71  73   2  71  73   2  72   2   2   2   2   2  94\n",
      " 131  94  94  94  94  94  80  58 157  80 157  80  49 157]\n",
      "Taking the seed tune as follows:\n",
      "[ 73  50 109 109 109  85 161  39  39  39 167 161  39  36 119   8  50 109\n",
      " 118 161  39  53 101  19  19  19 101  19  19  19  22 107]\n",
      "Taking the seed tune as follows:\n",
      "[130  67  88  29  27 162 155 106 155  34 155 106  27 167 155  45 155  96\n",
      " 155  45  27  20 155  51 106 155  27  82 128 106 155  79]\n",
      "Taking the seed tune as follows:\n",
      "[152  72 152  72   4 146   4 146   4 146 130 167   4 146  53  73  53  73\n",
      "  20  20  20  20  20  20  10  10  20  20  79  79  79  79]\n",
      "Taking the seed tune as follows:\n",
      "[163 162 163 167 163  26 102 163  39 163  48  97 163 167 163  99 102 163\n",
      "  39 163   3  97 163 167 163  26   8  98 102  98  19  98]\n"
     ]
    }
   ],
   "source": [
    "# Time to generate some Music!!!\n",
    "import random\n",
    "from Dataset import midi_helper \n",
    "\n",
    "# Assuming convert_to_midi() function only takes one argument\n",
    "for j in range(10):\n",
    "    index = random.randint(0, len(x_test))\n",
    "    print(\"Taking the seed tune as follows:\")\n",
    "    print(x_test[index])\n",
    "    tune = x_test[index]\n",
    "    input = np.empty((1, 32), dtype=int)\n",
    "    input[0] = tune\n",
    "    input = torch.from_numpy(input)\n",
    "    next_preds = 64\n",
    "    for i in range(next_preds):\n",
    "        output = Net(input.to(device), input.shape[0])\n",
    "        next_preds = np.argmax(output.cpu().detach().numpy(), axis=1)\n",
    "        input = input.cpu().detach().numpy()\n",
    "        input = torch.from_numpy(np.array([np.append(j, next_preds[ind]) \n",
    "                                           for ind, j in enumerate(input)])[:, 1:])\n",
    "        tune = np.insert(tune, -1, next_preds[0])\n",
    "    tune = [unique_notes[i] for i in tune]\n",
    "    path = './Outputs/music1'+str(j)+'.midi'\n",
    "    midi_helper.convert_to_midi(tune)  # Remove the path argument\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taking the seed tune as follows:\n",
      "[ 38  79  53  78  78  74  44  78  78  91 112 112  91 140 140  74 112 112\n",
      "  74 140 140  83  83 112 112  83  83 140 140  17  69  91]\n",
      "Saving file at: ./Outputs/music0.midi\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "convert_to_midi() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 31\u001b[0m\n\u001b[0;32m     29\u001b[0m path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_directory, filename)  \u001b[38;5;66;03m# Get the full path\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSaving file at:\u001b[39m\u001b[38;5;124m\"\u001b[39m, path)  \u001b[38;5;66;03m# Display the full path\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m \u001b[43mmidi_helper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_midi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtune\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: convert_to_midi() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from Dataset import midi_helper \n",
    "\n",
    "# Assuming convert_to_midi() function only takes one argument\n",
    "output_directory = './Outputs/'\n",
    "os.makedirs(output_directory, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "\n",
    "for j in range(10):\n",
    "    index = random.randint(0, len(x_test))\n",
    "    print(\"Taking the seed tune as follows:\")\n",
    "    print(x_test[index])\n",
    "    tune = x_test[index]\n",
    "    input = np.empty((1, 32), dtype=int)\n",
    "    input[0] = tune\n",
    "    input = torch.from_numpy(input)\n",
    "    next_preds = 64\n",
    "    for i in range(next_preds):\n",
    "        output = Net(input.to(device), input.shape[0])\n",
    "        next_preds = np.argmax(output.cpu().detach().numpy(), axis=1)\n",
    "        input = input.cpu().detach().numpy()\n",
    "        input = torch.from_numpy(np.array([np.append(j, next_preds[ind]) \n",
    "                                           for ind, j in enumerate(input)])[:, 1:])\n",
    "        tune = np.insert(tune, -1, next_preds[0])\n",
    "    tune = [unique_notes[i] for i in tune]\n",
    "    filename = f'music{j}.midi'\n",
    "    path = os.path.join(output_directory, filename)  # Get the full path\n",
    "    print(\"Saving file at:\", path)  # Display the full path\n",
    "    midi_helper.convert_to_midi(tune, path)  # Provide the full path argument\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install music21\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taking the seed tune as follows:\n",
      "[ 45 111  45  10 111 146 108 171  11  45  11  81  45 115 117 171   4  45\n",
      "   4   6  45   9   4 171  45 111  45 127 111 146 114 111]\n",
      "Taking the seed tune as follows:\n",
      "[129 159  50 159  16 159 129  56  55 171 125  89  56 129  56  16 161  16\n",
      " 114 113 114  50 114  16 113  19 113  66 129  66 129  68]\n",
      "Taking the seed tune as follows:\n",
      "[108 167 167 167 135  43 167 167 167  20 167 167 167 133 167 167 167 135\n",
      " 167 167 167  43  91 167 167 167 107 167 167  43 167  90]\n",
      "Taking the seed tune as follows:\n",
      "[ 57  46   4 172 160  13  41 160  22  75  57  46  60  80  46  76  31  46\n",
      "  11  31   4 164 144  76  31  46  11  31   4 164 144  76]\n",
      "Taking the seed tune as follows:\n",
      "[107 160  80 107 156 149 107 123  80 107  99  85 107  39 167  62 107  39\n",
      " 167  62 107  39 167  71  62 107  10 111 107 160 115 107]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from Dataset import midi_helper \n",
    "\n",
    "# Assuming convert_to_midi() function only takes one argument\n",
    "output_directory = './Outpu/'\n",
    "os.makedirs(output_directory, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "\n",
    "for j in range(5):\n",
    "    index = random.randint(0, len(x_test))\n",
    "    print(\"Taking the seed tune as follows:\")\n",
    "    print(x_test[index])\n",
    "    tune = x_test[index]\n",
    "    input = np.empty((1, 32), dtype=int)\n",
    "    input[0] = tune\n",
    "    input = torch.from_numpy(input)\n",
    "    next_preds = 64\n",
    "    for i in range(next_preds):\n",
    "        output = Net(input.to(device), input.shape[0])\n",
    "        next_preds = np.argmax(output.cpu().detach().numpy(), axis=1)\n",
    "        input = input.cpu().detach().numpy()\n",
    "        input = torch.from_numpy(np.array([np.append(j, next_preds[ind]) \n",
    "                                           for ind, j in enumerate(input)])[:, 1:])\n",
    "        tune = np.insert(tune, -1, next_preds[0])\n",
    "    tune = [unique_notes[i] for i in tune]\n",
    "    filename = f'music{j}.midi'\n",
    "    path = os.path.join(output_directory, filename)  # Get the full path\n",
    "    print(\"Saving file at:\", path)  # Display the full path\n",
    "    midi_helper.convert_to_midi(tune)  # Remove the path argument\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (2195820652.py, line 38)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[29], line 38\u001b[1;36m\u001b[0m\n\u001b[1;33m    midi_helper.convert_to_midi(f{timestamp}tune)  # Remove the path argument\u001b[0m\n\u001b[1;37m                                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from Dataset import midi_helper \n",
    "\n",
    "# Assuming convert_to_midi() function only takes one argument\n",
    "output_directory = './Outpu/'\n",
    "os.makedirs(output_directory, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "\n",
    "for j in range(5):\n",
    "    index = random.randint(0, len(x_test))\n",
    "    print(\"Taking the seed tune as follows:\")\n",
    "    print(x_test[index])\n",
    "    tune = x_test[index]\n",
    "    input = np.empty((1, 32), dtype=int)\n",
    "    input[0] = tune\n",
    "    input = torch.from_numpy(input)\n",
    "    next_preds = 64\n",
    "    for i in range(next_preds):\n",
    "        output = Net(input.to(device), input.shape[0])\n",
    "        next_preds = np.argmax(output.cpu().detach().numpy(), axis=1)\n",
    "        input = input.cpu().detach().numpy()\n",
    "        input = torch.from_numpy(np.array([np.append(j, next_preds[ind]) \n",
    "                                           for ind, j in enumerate(input)])[:, 1:])\n",
    "        tune = np.insert(tune, -1, next_preds[0])\n",
    "    tune = [unique_notes[i] for i in tune]\n",
    "    \n",
    "    from datetime import datetime\n",
    "    #timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = f'music_{timestamp}.midi'\n",
    "    \n",
    "    #filename = f'{timestamp}music{j}.midi'\n",
    "    path = os.path.join(output_directory, filename)  # Get the full path\n",
    "    print(\"Saving file at:\", path)  # Display the full path\n",
    "      # Remove the path argument\n",
    "    musiccc = midi_helper.convert_to_midi(tune)\n",
    "    \n",
    "    #from datetime import datetime\n",
    "#     current_directory = os.getcwd()\n",
    "#     midi_file_name = \"music.midi\"\n",
    "#     timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")  # Add timestamp to the file name\n",
    "#     new_midi_file_name = f\"music_{timestamp}.mid\"  # New unique file name\n",
    "#     #midi_file_path = os.path.join(current_directory, new_midi_file_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
